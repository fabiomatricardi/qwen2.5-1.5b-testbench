# qwen2.5-1.5b-testbench
run GGUF qwen2.5-1.5b with llamaCPP-python
